<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on SX-Aurora TSUBASA</title>
    <link>https://sx-aurora-dev.github.io/blog/tags/tensorflow/</link>
    <description>Recent content in tensorflow on SX-Aurora TSUBASA</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 23 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://sx-aurora-dev.github.io/blog/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deep Reinforcement Learning on SX-Aurora</title>
      <link>https://sx-aurora-dev.github.io/blog/post/20190823-dqn/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sx-aurora-dev.github.io/blog/post/20190823-dqn/</guid>
      <description>Our partner has evaluated their deep reinforcement learning algorithm on SX-Aurora&amp;rsquo;s Vector Engine. The result is very impressive. SX-Aurora outperforms GPU(P100) system about two times.
Their algorithm is based on &amp;ldquo;dueling double DQN&amp;rdquo; and solves 3D bin packing problems such as packing multiple products in boxes in a logistics center, loading packages into a truck, etc.
Since they are using TensorFlow, it can run on VE with TensorFlow for VE without special modification.</description>
    </item>
    
    <item>
      <title>Performance of TensorFlow on SX-Aurora</title>
      <link>https://sx-aurora-dev.github.io/blog/post/20190708-tf-perf/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sx-aurora-dev.github.io/blog/post/20190708-tf-perf/</guid>
      <description>We are investigating how SX-Aurora works on variouse ML applications. In this post, we would like to share the result of performance evaluation of three ML workloads using TensorFlow.
The graphs show relative performance of training on CPU, GPU and VE in SX-Aurora.
The left graph is simple CNN for image classification based on the example in Keras. We have used mnist dataset. As you know, GPU&amp;rsquo;s high peak computational performance works well for convolution layers, then V100 is the best.</description>
    </item>
    
    <item>
      <title>Release TensorFlow for SX-Aurora</title>
      <link>https://sx-aurora-dev.github.io/blog/post/20190605-tf-release/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sx-aurora-dev.github.io/blog/post/20190605-tf-release/</guid>
      <description>We are pleased to announce the release of TensorFlow for SX-Aurora. This TF supports Vector Engin in SX-Aurora as a computing device. We have implemented some kernels for VE. Such kenrels are offloaded to VE for acceleration.
We have also released:
 keras includes small modification for VE, vetfkernel includes implemetation of kernels for VE, and vednn is Vector Engine DNN Library.  You can pip install prebuild packages to start to use TF on SX-Aurora.</description>
    </item>
    
  </channel>
</rss>